[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction",
    "section": "",
    "text": "The introduction page for the student loan forgiveness text analysis project."
  },
  {
    "objectID": "data_newsapi.html",
    "href": "data_newsapi.html",
    "title": "Data - NewsAPI",
    "section": "",
    "text": "Part of the discussion surrounding Student Loan Forgiveness is reporting done by different news media organizations. These organizations generally align with a certain political bias. With the realization that those on the left tend to support at least some form of student loan relief and those on the right tend to oppose it, it could be fruitful to pair news organizations with their political biases. To achieve this, two main sources of news related data were explored:\n\nNewsAPI\nAllSides\n\n\n\nNewsAPI maintains an application programming interfacae (API) which returns information on articles published around the world. For the scope of this analysis, two search parameters were queried from the API. Articles were gathered using the specific search parameter of student loan forgiveness, as well as a general search parameter of student loans.\nThe data is initially returned in JSON format, which was then turned into a dataframe and subsequently exported into a csv file.\n\n\nSample of the Raw NewsAPI Data:\n\n\n\n\n    \n      \n      author\n      content\n      description\n      date\n      source\n      title\n      url\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the internet...\n(need help?)\n\n\n\n\n\n\nColumns:\n\nauthor\ncontent\ndescription\ndate\nsource\ntitle\nurl\n\n\n\n\n\nOne limitation of NewsAPI is that it doesn’t return the content of an article in its entirety. To account for this, numerous web scrapers were built for sources which were both scraping-eligible and appropriate for this analysis. This did reduce the number of sources and articles in the data from NewsAPI, but did result in complete article content. A list of eligible sources and their related scrapers were iteratively called to populate a dataframe with the individual paragraphs from the url associated with the article. To specify, the initial scrape through will result in a dataframe where each paragraph from the each scrapable article will have its own row.\n\n\nSample of the Raw Scraped Data:\n\n\n\n\n    \n      \n      source\n      url\n      paragraph\n      paragraph_num\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the internet...\n(need help?)\n\n\n\n\n\n\nColumns:\n\nsource\nurl\nparagraph\nparagraph_num\n\n\nUsing the source and url columns as keys, these can recombined with the columns from the original extraction of data for future use.\n\n\n\n\n\nAllSides is a community-based political bias rating platform for media. Using web scraping, biases for the sources in the scraped data were accumulated. Pages (urls) containing information on sources were scraped and manually found, which were then in turned scraped for their specific bias ratings.\n\n\nSample of the AllSides Data:\n\n\n\n\n    \n      \n      source\n      url\n      Bias Numeric\n      Bias Specific\n      Type\n      Region\n      Website\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the internet...\n(need help?)\n\n\n\n\n\n\nColumns:\n\nsource\nurl\nBias Numeric\nBias Specific\nType\nRegion\nWebsite\n\n\n\n\n\nThus far, raw data from an API and an array of web scraping functions has been gathered. This can now be combined together to create potential labels for the complete articles associated with the NewsAPI extraction. However, some data cleaning should be performed first.\n\n\nNewsAPI Extraction:\n\nauthor\n\nduplicate authors from same article removed\nemail addresses and links removed\nstripped of leading, trailing, and multiple spaces\nif author is None then the entry from the source column is used in place\nline breaks removed\n\ndescription\n\ntext before and including delimiters removed (i.e. delimiter could be “Date and Location –”)\n\ncontent\n\nignored in lieu of scraping the entire itself\n\n\nNewsAPI Scraping Extraction:\n\nparagraph\n\nblank paragraphs removed\nnon-breaking space characters removed (i.e. “”)\nstripped of leading, trailing, and multiple spaces\nall paragraphs of a single article combined post-cleaning\n\n\nAllSides Bias Ratings: no cleaning was required for this data, however a source-to-source map was created, as some sources were not identical between NewsAPI and AllSides.\n\n\n\nThe data with the completely scraped articles still retained the columns for source and url. Using those, the cleaned extraction columns can be merged in as well as the biases.\nThis resulted in a dataframe with the following columns:\n\nsource\nurl\narticle\nsource_bias\nBias Numeric\nBias Specific\nauthor\ndate\ntitle\nsearch\n\nWhere the text data itself will likely be article, but interesting analyses could be extended by using description or title.\nThe main label of interest will be Bais Specific, but interesting analyses could hinge upon using source, author, date, or search (topic query parameter).\nSample of the final labeled data:\n\n\n\n\n    \n      \n      source\n      url\n      article\n      source_bias\n      Bias Numeric\n      Bias Specific\n      author\n      description\n      date\n      title\n      search\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the internet...\n(need help?)"
  },
  {
    "objectID": "data_newsapi.html#newsapi-extraction",
    "href": "data_newsapi.html#newsapi-extraction",
    "title": "Data - NewsAPI",
    "section": "",
    "text": "NewsAPI maintains an application programming interfacae (API) which returns information on articles published around the world. For the scope of this analysis, two search parameters were queried from the API. Articles were gathered using the specific search parameter of student loan forgiveness, as well as a general search parameter of student loans.\nThe data is initially returned in JSON format, which was then turned into a dataframe and subsequently exported into a csv file.\n\n\nSample of the Raw NewsAPI Data:\n\n\n\n\n    \n      \n      author\n      content\n      description\n      date\n      source\n      title\n      url\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the internet...\n(need help?)\n\n\n\n\n\n\nColumns:\n\nauthor\ncontent\ndescription\ndate\nsource\ntitle\nurl"
  },
  {
    "objectID": "data_newsapi.html#newsapi-scraping",
    "href": "data_newsapi.html#newsapi-scraping",
    "title": "Data - NewsAPI",
    "section": "",
    "text": "One limitation of NewsAPI is that it doesn’t return the content of an article in its entirety. To account for this, numerous web scrapers were built for sources which were both scraping-eligible and appropriate for this analysis. This did reduce the number of sources and articles in the data from NewsAPI, but did result in complete article content. A list of eligible sources and their related scrapers were iteratively called to populate a dataframe with the individual paragraphs from the url associated with the article. To specify, the initial scrape through will result in a dataframe where each paragraph from the each scrapable article will have its own row.\n\n\nSample of the Raw Scraped Data:\n\n\n\n\n    \n      \n      source\n      url\n      paragraph\n      paragraph_num\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the internet...\n(need help?)\n\n\n\n\n\n\nColumns:\n\nsource\nurl\nparagraph\nparagraph_num\n\n\nUsing the source and url columns as keys, these can recombined with the columns from the original extraction of data for future use."
  },
  {
    "objectID": "data_newsapi.html#allsides-bias-data",
    "href": "data_newsapi.html#allsides-bias-data",
    "title": "Data - NewsAPI",
    "section": "",
    "text": "AllSides is a community-based political bias rating platform for media. Using web scraping, biases for the sources in the scraped data were accumulated. Pages (urls) containing information on sources were scraped and manually found, which were then in turned scraped for their specific bias ratings.\n\n\nSample of the AllSides Data:\n\n\n\n\n    \n      \n      source\n      url\n      Bias Numeric\n      Bias Specific\n      Type\n      Region\n      Website\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the internet...\n(need help?)\n\n\n\n\n\n\nColumns:\n\nsource\nurl\nBias Numeric\nBias Specific\nType\nRegion\nWebsite"
  },
  {
    "objectID": "data_newsapi.html#cleaning-and-merging",
    "href": "data_newsapi.html#cleaning-and-merging",
    "title": "Data - NewsAPI",
    "section": "",
    "text": "Thus far, raw data from an API and an array of web scraping functions has been gathered. This can now be combined together to create potential labels for the complete articles associated with the NewsAPI extraction. However, some data cleaning should be performed first.\n\n\nNewsAPI Extraction:\n\nauthor\n\nduplicate authors from same article removed\nemail addresses and links removed\nstripped of leading, trailing, and multiple spaces\nif author is None then the entry from the source column is used in place\nline breaks removed\n\ndescription\n\ntext before and including delimiters removed (i.e. delimiter could be “Date and Location –”)\n\ncontent\n\nignored in lieu of scraping the entire itself\n\n\nNewsAPI Scraping Extraction:\n\nparagraph\n\nblank paragraphs removed\nnon-breaking space characters removed (i.e. “”)\nstripped of leading, trailing, and multiple spaces\nall paragraphs of a single article combined post-cleaning\n\n\nAllSides Bias Ratings: no cleaning was required for this data, however a source-to-source map was created, as some sources were not identical between NewsAPI and AllSides.\n\n\n\nThe data with the completely scraped articles still retained the columns for source and url. Using those, the cleaned extraction columns can be merged in as well as the biases.\nThis resulted in a dataframe with the following columns:\n\nsource\nurl\narticle\nsource_bias\nBias Numeric\nBias Specific\nauthor\ndate\ntitle\nsearch\n\nWhere the text data itself will likely be article, but interesting analyses could be extended by using description or title.\nThe main label of interest will be Bais Specific, but interesting analyses could hinge upon using source, author, date, or search (topic query parameter).\nSample of the final labeled data:\n\n\n\n\n    \n      \n      source\n      url\n      article\n      source_bias\n      Bias Numeric\n      Bias Specific\n      author\n      description\n      date\n      title\n      search\n    \n  \n\n\n    \n        \n        \n        \n        \n        \n        \n        \n        \n    \n    \n   \n    \n      \n  \n        \n    \n    \n  \n        \n    \n    \n  \n        \n    \n      \n  \n        \n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n\n            \n                \n                \n            \n        \n    \n\n\nLoading ITables v2.2.4 from the internet...\n(need help?)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n\nCode\n1 + 1\n\n\n2"
  },
  {
    "objectID": "data_reddit.html",
    "href": "data_reddit.html",
    "title": "Data - Reddit",
    "section": "",
    "text": "Data acquired from Reddit."
  }
]